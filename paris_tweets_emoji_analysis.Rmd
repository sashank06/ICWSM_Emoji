```{r}
options(stringsAsFactors = FALSE)
library(slam)
library(magrittr)
library(textcat)
#library(cldr)
library(entropart)
#update.packages()
library(tidyverse)
#library(tokenizers)
library(mgcv)
library(twitteR)
library(plyr)
library(dplyr)
library(boot)
library(vegan)
library(simboot)
library(ROAuth)
library(stringr)
library(readxl)
library(stringi)
library(stringr)
library(tidytext)
library(tidyr)
library(dplyr)
library(tm)
library(scales)
library(reshape2)
library(ggplot2)
#library(sentiment)
library(SnowballC)
library(tm)
library(RColorBrewer)
```


#Load the data from the csv file
```{r}
#setwd("/Users/vsriniv6/Documents/paris_data")
data_paris = read.csv2(file="paris_timeseries_countries.csv",header=TRUE,sep=",",encoding="UTF-8")
```

```{r}
data_paris
```

#Separate the tweets into solidarity and non-solidarity tweets
```{r}
data_solidarity = subset(data_paris, labels==1)
data_non_solidarity = subset(data_paris, labels==-1)
```



#Number of solidarity and non-solidarity tweets
```{r}
nrow(data_solidarity)
nrow(data_non_solidarity)
```

#get the solidarity tweets from the dataframe 
```{r}

sol_tweets <- data_solidarity %>% select(text) 
sol_tweets <- unique(sol_tweets)
```


#get the non-solidarity tweets from the dataframe 
```{r}

non_sol_tweets <- data_non_solidarity %>% select(text) 
non_sol_tweets <- unique(non_sol_tweets)
```

#Load the emoji dictionary containing emoji's and the unicode values
```{r}
emDict_raw <- read.csv2("emDict.csv",sep=";") %>% 
      select(EN, utf8, unicode) %>% 
      dplyr::rename(description = EN, r.encoding = utf8)
```

#pre-process skin ones if necessary
```{r}
# plain skin tones
skin_tones <- c("light skin tone", 
                "medium-light skin tone", 
                "medium skin tone",
                "medium-dark skin tone", 
                "dark skin tone")

# remove plain skin tones and remove skin tone info in description
emDict <- emDict_raw %>%
  # remove plain skin tones emojis
  filter(!description %in% skin_tones) %>%
  # remove emojis with skin tones info, e.g. remove woman: light skin tone and only
  # keep woman
 filter(!grepl(":", description)) %>%
 mutate(description = tolower(description)) %>%
 mutate(unicode = unicode)
```

#get the rank of emoji's in solidarity tweets
```{r}
new_rank_solidarity <- data_solidarity%>%
  group_by(description)%>% 
  dplyr::summarise(count = sum(count)) %>%arrange(-count) 
```

#Filter out tweets with the description "None"
```{r}
raw_texts_paris_sol <- data_solidarity %>% 
  #mutate(text = cleanPosts(text)) %>%
  filter(text != "") %>% 
  filter(description!="None")
```


##get the rank of top 10 emoji's
```{r}
res_rank<-head(new_rank_solidarity, 10)
res_rank
```

#Merge the emoji dictionary with the rank data frame to obtain unicode values for each emoji's
```{r}
res <- merge(res_rank, emDict, by.x = "description", by.y = "description")
res
```
##add variation selector to the red heart to ensure correct display
```{r}
res$unicode[res$description=="red heart"] <- 'U+2764 U+FE0F'
```

```{r}
conv_unicode = as.character(parse(text=shQuote(gsub("U\\+([A-Z0-9]+)", "\\\\U\\1", res$unicode))))
conv_unicode = gsub("[[:space:]]", "", conv_unicode) 
conv_unicode = gsub("u2764", "u2764\\ufe0f", conv_unicode) 
conv_unicode
```

##Frequency chart showing top ten emoji's
```{r}

library(emojifont)
library(ggplot2)
library(gridSVG)
load.emojifont("OpenSansEmoji.ttf")
list.emojifonts()
quartz()
ggplot(res, aes(reorder(description,-count), sprintf("%0.2f", round(count, digits = 2)), label = c(conv_unicode))) +
  geom_bar(stat = "identity") +
  geom_text(col= 'blue',family = "OpenSansEmoji", size = 6, vjust = -.5) +
  scale_x_discrete(breaks = res$description, labels = c(conv_unicode)) +
  ylab("Frequency") +
  theme(axis.title.x=element_blank(),
        axis.text.x=element_blank(),
    axis.ticks.x=element_blank())
ps = grid.export("emoji_solidarity_paris.svg", addClass=T)
```



##Create data table containing emoji's grouping by each tweet and country
```{r}
#install.packages("qdap")
library(data.table)
emoj_sol_lis_paris<-as.data.table(emoji_paris_sol)[, toString(description), by = list(text,country)]
#emoj_sol_lis_paris$V1
```

##get the tweets and emoji's from France
```{r}
emoj_sol_lis_paris_France = emoj_sol_lis_paris[which(country=="France")]
```


#get the frequency of each emoji
```{r}
library(stringr)
emoj_sol_lis_paris_France$V1 %>%
  str_split(", | and ") %>%
  unlist %>%
  table %>%
  data.frame %>%
  arrange(-Freq) %>%
  filter(Freq > 1)
```

##construct a weighted edge list
```{r}
e <- emoj_sol_lis_paris_France$V1  %>%
  str_split(", | and ") %>%
  lapply(function(x) {
    expand.grid(x, x, w = 1 / length(x),stringsAsFactors = FALSE)
  }) %>%
  bind_rows

e <- apply(e[, -3], 1, str_sort) %>%
  t %>%
  data.frame(stringsAsFactors = FALSE) %>%
   mutate(w = e$w)
```


#remove keywords connected to themselves in cooccurence pairs
```{r}
e <- group_by(e, X1, X2) %>%
  dplyr::summarise(w=sum(w)) %>% arrange(-w)%>%
  filter(X1 != X2)

```

#construct a weighted network
```{r}
#install.packages("igraph")
#install.packages("tnet")
library(tnet)
library(igraph)
library(intergraph)
library(ggnetwork)
library(network)
library(dplyr)
library(ggplot2)
n <- network(e[, -3], directed = FALSE)

stopifnot(nrow(e) == network.edgecount(n))
network::set.edge.attribute(n, "weight", e$w)

# weighted degree at alpha = 1
t <- as.edgelist(n, attrname = "weight") %>%
  symmetrise_w %>%
  as.tnet %>%
  degree_w

stopifnot(nrow(t) == network.size(n))
network::set.vertex.attribute(n, "degree_w", t[, "output" ])
```


#remove the nodes with a low weighted degree from consideration
```{r}
l <- n %v% "degree_w"
#l

l <- ifelse(l>=median(l),network.vertex.names(n), NA)

stopifnot(length(l) == network.size(n))
#l <- l[!is.na(l)]
#network::set.vertex.attribute(n, "label", l)
```



```{r}
l <- rbind(l, data.frame(description = l))
```



#merge with the emoji dictionary to get unicode value for each emoji
```{r}
res_sol <- merge(l, emDict, by.x = "description", by.y = "description")
res_sol
```
##add variation selector to the red heart to ensure correct display
```{r}
res_sol$unicode[res_sol$description=="red heart"] <- 'U+2764 U+FE0F'
```



```{r}
conv_unicode_paris_sol = as.character(parse(text=shQuote(gsub("U\\+([A-Z0-9]+)", "\\\\U\\1", l_sol$unicode))))
conv_unicode_paris_sol = gsub("[[:space:]]", "", conv_unicode_paris_sol) 
#conv_unicode_paris_sol
#class(conv_unicode_paris_sol)
network::set.vertex.attribute(n, "label", c(conv_unicode_paris_sol))

```

```{r}
conv_unicode_paris_sol
```


#create coocurrence network
```{r}
#library(emojifont)
library(ggplot2)
library(gridSVG)

quartz()

ggnetwork(n,layout = "fruchtermanreingold",weights = "weight",n_iter=1500) %>%
ggplot(aes(x, y, xend = xend, yend = yend)) +
  geom_edges(color="grey80")+
  geom_nodetext(aes(label = label),check_overlap=TRUE) +
  scale_size_continuous(range = c(6, 6)) +
  scale_color_gradient2(low = "grey25", midpoint = 0.75, high = "black") +
  guides(size = FALSE, color = FALSE) + 
  theme_blank()
ps=grid.export("emoji_solidarity_paris_network_France.svg", addClass=T)
```


#get the tweets from outside France
```{r}
emoj_sol_lis_paris_ExceptFrance = emoj_sol_lis_paris[which(country!="France" & country!="None")]
```

##get the frequencies of emoji's
```{r}
library(stringr)
emoj_sol_lis_paris_ExceptFrance$V1 %>%
  str_split(", | and ") %>%
  unlist %>%
  table %>%
  data.frame %>%
  arrange(-Freq) %>%
  filter(Freq > 1)
```


##construct a weighted edge list
```{r}
e <- emoj_sol_lis_paris_ExceptFrance$V1  %>%
  str_split(", | and ") %>%
  lapply(function(x) {
    expand.grid(x, x,w = 1 / length(x), stringsAsFactors = FALSE)
  }) %>%
  bind_rows

e <- apply(e[, -3], 1, str_sort) %>%
  t %>%
  data.frame(stringsAsFactors = FALSE) %>%
  mutate(w = e$w)
```

#remove keywords connected to themselves in cooccurence pairs
```{r}
e <- group_by(e, X1, X2) %>%
  dplyr::summarise(w=sum(w)) %>% arrange(-w) %>%
  filter(X1 != X2)


```



#construct a weighted network
```{r}
#install.packages("igraph")
#install.packages("tnet")
library(tnet)
library(igraph)
library(intergraph)
library(ggnetwork)
library(network)
library(dplyr)
library(ggplot2)
n <- network(e[, -3], directed = FALSE)

stopifnot(nrow(e) == network.edgecount(n))
network::set.edge.attribute(n, "weight", e$w)

# weighted degree at alpha = 1
t <- as.edgelist(n, attrname = "weight") %>%
  symmetrise_w %>%
  as.tnet %>%
  degree_w

stopifnot(nrow(t) == network.size(n))
network::set.vertex.attribute(n, "degree_w", t[, "output" ])
```


```{r}
l <- n %v% "degree_w"
#l

l <- ifelse(l >= median(l), network.vertex.names(n), NA)

stopifnot(length(l) == network.size(n))
#l <- l[!is.na(l)]
#network::set.vertex.attribute(n, "label", l)
```





```{r}
l <- rbind(l, data.frame(description = l))
```



#merge with the emoji dictionary to get unicode value for each emoji
```{r}
res_sol <- merge(l, emDict, by.x = "description", by.y = "description")
res_sol
```


##add variation selector to the red heart to ensure correct display
```{r}
res_sol$unicode[res_sol$description=="red heart"] <- 'U+2764 U+FE0F'
```


```{r}

conv_unicode_paris_sol = as.character(parse(text=shQuote(gsub("U\\+([A-Z0-9]+)", "\\\\U\\1", l_sol$unicode))))
conv_unicode_paris_sol = gsub("[[:space:]]", "", conv_unicode_paris_sol) 
#conv_unicode_paris_sol
#class(conv_unicode_paris_sol)
#network::set.vertex.attribute(n, "label", conv_unicode_paris_sol)
network::set.vertex.attribute(n, "label", conv_unicode_paris_sol)
network.vertex.names(n) <- conv_unicode_paris_sol
```



#create cooccurence network
```{r}
library(emojifont)
library(ggplot2)
library(gridSVG)
load.emojifont("OpenSansEmoji.ttf")
list.emojifonts()
quartz()
ggnetwork(n,layout = "fruchtermanreingold",weights = "weight",n_iter=1500) %>%
ggplot(aes(x, y, xend = xend, yend = yend)) +
  geom_edges(color="grey80")+
  geom_nodetext(aes(label = label),check_overlap=TRUE) +
  scale_size_continuous(range = c(6, 6)) +
  scale_color_gradient2(low = "grey25", midpoint = 0.75, high = "black") +
  guides(size = FALSE, color = FALSE) + 
  theme_blank()
ps = grid.export("emoji_solidarity_paris_network_NotFrance.svg", addClass=T)
```






